Reflection

We compared ChatGPT and Claude, each tested under zero-shot and careful prompting.

ChatGPT zero-shot produced reasonably structured use cases but often with thin sections, especially missing or underdeveloped subflows and alternatives. With careful prompting, ChatGPT outputs became consistent: each use case followed the required four-section format and addressed relevant details such as tax categories, refunds, and cross-jurisdiction rules.

Claude zero-shot generated a broad set of 30 use cases quickly, introducing diverse scenarios like catering orders, health inspections, and surge pricing. However, its structure was less reliable, with several use cases condensed to only a few lines. Under careful prompting, Claude produced more formally organized use cases with thorough subflows and alternative flows. It also captured regulatory and administrative complexity better than ChatGPT, though it sometimes created overlapping scenarios that required deduplication.

Careful prompting clearly improved both models. ChatGPT was stronger in maintaining the expected structure, while Claude was stronger in variety and creativity. Using both together and merging their results provided the most complete coverage of system roles, payment methods, and regulatory constraints.

Cost: The total API cost was $0.67 for Claude and $0.47 for ChatGPT, resulting in a combined cost of $1.14. This is well under the $80 project budget (â‰ˆ$20 per person).

Conclusion: ChatGPT with careful prompting is the most reliable for structure, while Claude contributes useful breadth and edge cases. Together, they provide a robust foundation for the expanded set of use cases.